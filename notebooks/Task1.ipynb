{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3094faa8-e730-494c-8864-1e3ff2af77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-play-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84ea6eb9-6cb7-4029-9da6-799a8ed8deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google_play_scraper import reviews, Sort\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "BANK_APPS = {\n",
    "    'Commercial Bank of Ethiopia': {\n",
    "        'app_id': 'com.combanketh.mobilebanking',\n",
    "        'count': 1000\n",
    "    },\n",
    "    'Bank of Abyssinia': {\n",
    "        'app_id': 'com.boa.boaMobileBanking',\n",
    "        'count': 1500\n",
    "    },\n",
    "    'Dashen Bank': {\n",
    "        'app_id': 'com.dashen.dashensuperapp',\n",
    "        'count': 7000\n",
    "    }\n",
    "}\n",
    "MIN_REQUIRED = 400\n",
    "OUTPUT_FILE = 'all_banks_reviews_cleaned.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3989b2a-7154-4164-bdeb-e4d8324cbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Function\n",
    "def scrape_reviews(app_id, bank_name, count):\n",
    "    print(f\" Scraping up to {count} reviews for {bank_name}...\")\n",
    "    result, _ = reviews(\n",
    "        app_id,\n",
    "        lang='en',\n",
    "        country='us',\n",
    "        sort=Sort.NEWEST,\n",
    "        count=count,\n",
    "        filter_score_with=None\n",
    "    )\n",
    "    actual_count = len(result)\n",
    "    print(f\"{bank_name}: Scraped {actual_count} reviews from Google Play\\n\")\n",
    "\n",
    "    df = pd.DataFrame(result)\n",
    "    df['bank'] = bank_name\n",
    "    df['source'] = 'Google Play'\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887fa5b3-3b0f-4c8a-a939-e14a241b0a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Scraping up to 1000 reviews for Commercial Bank of Ethiopia...\n",
      "Commercial Bank of Ethiopia: Scraped 1000 reviews from Google Play\n",
      "\n",
      " Cleaning: Commercial Bank of Ethiopia\n",
      "➖ Dropped 0 rows with missing values\n",
      "➖ Dropped 0 duplicate reviews\n",
      "Commercial Bank of Ethiopia: 1000 cleaned reviews\n",
      "\n",
      " Scraping up to 1500 reviews for Bank of Abyssinia...\n",
      "Bank of Abyssinia: Scraped 1044 reviews from Google Play\n",
      "\n",
      " Cleaning: Bank of Abyssinia\n",
      "➖ Dropped 0 rows with missing values\n",
      "➖ Dropped 0 duplicate reviews\n",
      "Bank of Abyssinia: 1044 cleaned reviews\n",
      "\n",
      " Scraping up to 7000 reviews for Dashen Bank...\n",
      "Dashen Bank: Scraped 449 reviews from Google Play\n",
      "\n",
      " Cleaning: Dashen Bank\n",
      "➖ Dropped 0 rows with missing values\n",
      "➖ Dropped 0 duplicate reviews\n",
      "Dashen Bank: 449 cleaned reviews\n",
      "\n",
      "\n",
      " All banks processed. Combined file saved as: all_banks_reviews_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Clean Function \n",
    "def clean_reviews(df, bank_name):\n",
    "    print(f\" Cleaning: {bank_name}\")\n",
    "    df.rename(columns={'content': 'review', 'score': 'rating'}, inplace=True)\n",
    "    if 'at' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['at'], errors='coerce')\n",
    "\n",
    "    # Drop rows with missing essential data\n",
    "    before_drop = len(df)\n",
    "    df = df.dropna(subset=['review', 'rating', 'date'])\n",
    "    after_drop = len(df)\n",
    "    print(f\"➖ Dropped {before_drop - after_drop} rows with missing values\")\n",
    "\n",
    "    # Drop duplicates\n",
    "    before_dup = len(df)\n",
    "    df = df.drop_duplicates(subset=['review', 'date'])\n",
    "    after_dup = len(df)\n",
    "    print(f\"➖ Dropped {before_dup - after_dup} duplicate reviews\")\n",
    "\n",
    "    # Format date\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    return df[['review', 'rating', 'date', 'bank', 'source']]\n",
    "\n",
    "\n",
    "all_cleaned = []\n",
    "for bank, info in BANK_APPS.items():\n",
    "    raw_df = scrape_reviews(info['app_id'], bank, info['count'])\n",
    "    clean_df = clean_reviews(raw_df, bank)\n",
    "    print(f\"{bank}: {len(clean_df)} cleaned reviews\\n\")\n",
    "\n",
    "    if len(clean_df) >= MIN_REQUIRED:\n",
    "        all_cleaned.append(clean_df)\n",
    "    else:\n",
    "        print(f\"{bank}: Skipped — only {len(clean_df)} valid reviews.\\n\")\n",
    "\n",
    "# Save final result\n",
    "if len(all_cleaned) == len(BANK_APPS):\n",
    "    final_df = pd.concat(all_cleaned, ignore_index=True)\n",
    "    final_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8')\n",
    "    print(f\"\\n All banks processed. Combined file saved as: {OUTPUT_FILE}\")\n",
    "else:\n",
    "    print(\"\\n Not all banks met the minimum review count. File not saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21162d7d-6b88-48b3-9fae-8dbf93c17229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
